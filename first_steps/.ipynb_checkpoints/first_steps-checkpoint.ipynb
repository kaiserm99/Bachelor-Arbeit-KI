{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planen: ./../../libMultiRobotPlanning-master/build/ecbs -i test.yaml -o output.yaml\n",
    "\n",
    "Visualisieren:\n",
    "python3 ../../libMultiRobotPlanning-master/example/visualize.py test.yaml output.yaml\n",
    "\n",
    "Basic Info:\n",
    "[North, East, South, West]\n",
    "DO_NOTHING= 0 MOVE_FORWARD= 2 MOVE_LEFT= 1 MOVE_RIGHT= 3 STOP_MOVING= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from typing import Optional, List, Dict\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from flatland.core.env import Environment\n",
    "from flatland.core.env_observation_builder import ObservationBuilder\n",
    "from flatland.core.grid.grid_utils import coordinate_to_position\n",
    "from flatland.envs.predictions import ShortestPathPredictorForRailEnv\n",
    "from flatland.envs.rail_env import RailEnv\n",
    "from flatland.envs.rail_generators import complex_rail_generator\n",
    "from flatland.envs.schedule_generators import complex_schedule_generator\n",
    "from flatland.utils.ordered_set import OrderedSet\n",
    "from flatland.utils.rendertools import RenderTool\n",
    "from flatland.core.grid.grid4_utils import get_new_position\n",
    "\n",
    "from flatland.utils.misc import str2bool\n",
    "\n",
    "\n",
    "random.seed(100)\n",
    "np.random.seed(100)\n",
    "\n",
    "direction_to_str = {0: \"North\", 1: \"East\", 2: \"South\", 3: \"West\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstStepsAgent:\n",
    "\n",
    "    def __init__(self, schedule, handle):\n",
    "        self.step = 0\n",
    "        self.iterations = 100\n",
    "        \n",
    "        self.schedule = schedule\n",
    "        self.handle = handle\n",
    "        \n",
    "        self.computed_schedule = []\n",
    "        self.start_own_schedule = False\n",
    "        \n",
    "        \n",
    "\n",
    "    def act(self, obs):\n",
    "        \"\"\"\n",
    "        :param state: input is the observation of the agent\n",
    "        :return: returns an action\n",
    "        \"\"\"\n",
    "        \n",
    "        # \"Ignore\" the first step and just start with a forward move\n",
    "        if self.step == 0:\n",
    "            self.step += 1\n",
    "            return 2\n",
    "\n",
    "        \n",
    "        # If the count of steps is higher than the schedule, the agent is at the goal\n",
    "        if self.step >= len(self.schedule):\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "        # Get the position and the direction of the agent based on the observation\n",
    "        pos = obs.position\n",
    "        direction = obs.direction\n",
    "        \n",
    "        # The Agent has already reached the goal, maybe by compuing the schedule\n",
    "        if pos == None:\n",
    "            print(f\"<{self.handle}>, has reached the target!\")\n",
    "            self.step = len(self.schedule)\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "        # If there was an position, which wasn't reachable, then use the computed action path\n",
    "        if len(self.computed_schedule) > 0 and self.start_own_schedule:\n",
    "            \n",
    "            print(self.computed_schedule)\n",
    "            return self.computed_schedule.pop(0)\n",
    "    \n",
    "        # We have reached the end of the schedule and need to increase the steps by one\n",
    "        elif len(self.computed_schedule) == 0 and self.start_own_schedule:\n",
    "            self.start_own_schedule = False\n",
    "            self.step += 1\n",
    "        \n",
    "        \n",
    "        # Get the the calculated position where the agent has to move\n",
    "        goal = (self.schedule[self.step]['x'], self.schedule[self.step]['y'])\n",
    "\n",
    "\n",
    "        # Try one iteration to get to the calculated position\n",
    "        result = a_star(self.handle, pos, direction, goal, iterations=1)\n",
    "        \n",
    "        \n",
    "        # DEBUG\n",
    "        print(f\"{result}, from: {pos}, to: {goal}\")\n",
    "\n",
    "        \n",
    "\n",
    "        # The calculated scheudule is really bad, so it can be that the next position isn't reachable in one iteration\n",
    "        if result.status == A_Star_result.fail:\n",
    "            print(f\"<{self.handle}>, trys more iterations...\")\n",
    "        \n",
    "            \n",
    "            for i in range(2, len(self.schedule[self.step:])):\n",
    "                # Try to get to the next position in the calculated scheudule\n",
    "                self.step += 1\n",
    "                \n",
    "                goal = (self.schedule[self.step]['x'], self.schedule[self.step]['y'])\n",
    "                \n",
    "                # Increase the count of iterations to eventually reach the end\n",
    "                result = a_star(self.handle, pos, direction, goal, iterations= i ** i)\n",
    "                \n",
    "                if result.status == A_Star_result.succes:\n",
    "                    \n",
    "                    print(f\"<{self.handle}>, found the Solution Path: {result.actions} to {goal}\")\n",
    "                    \n",
    "                    self.start_own_schedule = True\n",
    "                    self.computed_schedule = result.actions[1:]\n",
    "                    \n",
    "                    print(result)\n",
    "                    \n",
    "                    return result.get_n_action(0)\n",
    "\n",
    "\n",
    "            else:\n",
    "                print(f\"Couln't find a Solution to a calculated traget!\")\n",
    "                \n",
    "\n",
    "        elif result.is_goal():\n",
    "            print(f\"<{self.handle}>, has reached the End!\")\n",
    "            self.step = len(self.schedule)\n",
    "            return 0\n",
    "\n",
    "\n",
    "        self.step += 1\n",
    "\n",
    "        return result.get_n_action(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Observation():\n",
    "    def __init__(self, position, direction, target):\n",
    "        self.position = position \n",
    "        self.direction = direction\n",
    "        self.target = target\n",
    "\n",
    "class ObservePredictions(ObservationBuilder):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def get_many(self, handles: Optional[List[int]] = None) -> Dict[int, np.ndarray]:\n",
    "        observations = {}\n",
    "        \n",
    "\n",
    "        # Collect all the different observation for all the agents\n",
    "        for h in handles:\n",
    "            observations[h] = self.get(h)\n",
    "\n",
    "        return observations\n",
    "\n",
    "    def get(self, handle: int = 0) -> np.ndarray:\n",
    "        \n",
    "        agent = self.env.agents[handle]\n",
    "        \n",
    "        # self.env.dev_pred_dict[handle] = get_computed_path(handle)\n",
    "        \n",
    "        return Observation(agent.position, agent.direction, agent.target)\n",
    "\n",
    "    def set_env(self, env: Environment):\n",
    "        super().set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open_window - pyglet\n",
      "\n",
      "<0> Action: |2|, Position: (13, 0), Target: (4, 2), Direction: South\n",
      "<1> Action: |2|, Position: (0, 2), Target: (7, 6), Direction: North\n",
      "<2> Action: |2|, Position: (5, 9), Target: (10, 2), Direction: East\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "Succes! actions: [2], positions: [(12, 0)], from: (13, 0), to: (12, 0)\n",
      "Succes! actions: [2], positions: [(1, 2)], from: (0, 2), to: (1, 2)\n",
      "Succes! actions: [2], positions: [(5, 8)], from: (5, 9), to: (5, 8)\n",
      "\n",
      "<0> Action: |2|, Position: (12, 0), Target: (4, 2), Direction: North\n",
      "<1> Action: |2|, Position: (1, 2), Target: (7, 6), Direction: South\n",
      "<2> Action: |2|, Position: (5, 8), Target: (10, 2), Direction: West\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "Succes! actions: [2], positions: [(11, 0)], from: (12, 0), to: (11, 0)\n",
      "Succes! actions: [2], positions: [(2, 2)], from: (1, 2), to: (2, 2)\n",
      "Succes! actions: [2], positions: [(5, 7)], from: (5, 8), to: (5, 7)\n",
      "\n",
      "<0> Action: |2|, Position: (11, 0), Target: (4, 2), Direction: North\n",
      "<1> Action: |2|, Position: (2, 2), Target: (7, 6), Direction: South\n",
      "<2> Action: |2|, Position: (5, 7), Target: (10, 2), Direction: West\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "Succes! actions: [2], positions: [(10, 0)], from: (11, 0), to: (10, 0)\n",
      "Succes! actions: [2], positions: [(3, 2)], from: (2, 2), to: (3, 2)\n",
      "Succes! actions: [2], positions: [(5, 6)], from: (5, 7), to: (5, 6)\n",
      "\n",
      "<0> Action: |2|, Position: (10, 0), Target: (4, 2), Direction: North\n",
      "<1> Action: |2|, Position: (3, 2), Target: (7, 6), Direction: South\n",
      "<2> Action: |2|, Position: (5, 6), Target: (10, 2), Direction: West\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "Succes! actions: [2], positions: [(9, 0)], from: (10, 0), to: (9, 0)\n",
      "Failed in 2 iterations..., from: (3, 2), to: (4, 2)\n",
      "<1>, trys more iterations...\n",
      "<1>, found the Solution Path: [1, 3, 1, 3, 1, 3, 1, 3, 2, 1, 3, 1, 2, 1] to (6, 3)\n",
      "Succes! actions: [1, 3, 1, 3, 1, 3, 1, 3, 2, 1, 3, 1, 2, 1], positions: [(3, 3), (4, 3), (4, 4), (5, 4), (5, 5), (6, 5), (6, 6), (7, 6), (6, 6), (6, 5), (5, 5), (5, 4), (5, 3), (6, 3)]\n",
      "Succes! actions: [1], positions: [(6, 6)], from: (5, 6), to: (6, 6)\n",
      "\n",
      "<0> Action: |2|, Position: (9, 0), Target: (4, 2), Direction: North\n",
      "<1> Action: |1|, Position: (3, 3), Target: (7, 6), Direction: East\n",
      "<2> Action: |1|, Position: (6, 6), Target: (10, 2), Direction: South\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "Succes! actions: [2], positions: [(8, 0)], from: (9, 0), to: (8, 0)\n",
      "[3, 1, 3, 1, 3, 1, 3, 2, 1, 3, 1, 2, 1]\n",
      "Failed in 2 iterations..., from: (6, 6), to: (7, 6)\n",
      "<2>, trys more iterations...\n",
      "<2>, found the Solution Path: [3, 1] to (7, 5)\n",
      "Succes! actions: [3, 1], positions: [(6, 5), (7, 5)]\n",
      "\n",
      "<0> Action: |2|, Position: (8, 0), Target: (4, 2), Direction: North\n",
      "<1> Action: |3|, Position: (4, 3), Target: (7, 6), Direction: South\n",
      "<2> Action: |3|, Position: (6, 5), Target: (10, 2), Direction: West\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "Succes! actions: [2], positions: [(7, 0)], from: (8, 0), to: (7, 0)\n",
      "[1, 3, 1, 3, 1, 3, 2, 1, 3, 1, 2, 1]\n",
      "[1]\n",
      "\n",
      "<0> Action: |2|, Position: (7, 0), Target: (4, 2), Direction: North\n",
      "<1> Action: |1|, Position: (4, 4), Target: (7, 6), Direction: East\n",
      "<2> Action: |1|, Position: (7, 5), Target: (10, 2), Direction: South\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "Succes! actions: [2], positions: [(6, 0)], from: (7, 0), to: (6, 0)\n",
      "[3, 1, 3, 1, 3, 2, 1, 3, 1, 2, 1]\n",
      "Succes! actions: [3], positions: [(7, 4)], from: (7, 5), to: (7, 4)\n",
      "\n",
      "<0> Action: |2|, Position: (6, 0), Target: (4, 2), Direction: North\n",
      "<1> Action: |3|, Position: (5, 4), Target: (7, 6), Direction: South\n",
      "<2> Action: |3|, Position: (7, 4), Target: (10, 2), Direction: West\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "Succes! actions: [3], positions: [(6, 1)], from: (6, 0), to: (6, 1)\n",
      "[1, 3, 1, 3, 2, 1, 3, 1, 2, 1]\n",
      "Succes! actions: [1], positions: [(8, 4)], from: (7, 4), to: (8, 4)\n",
      "\n",
      "<0> Action: |3|, Position: (6, 1), Target: (4, 2), Direction: East\n",
      "<1> Action: |1|, Position: (5, 5), Target: (7, 6), Direction: East\n",
      "<2> Action: |1|, Position: (8, 4), Target: (10, 2), Direction: South\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "Succes! actions: [1], positions: [(5, 1)], from: (6, 1), to: (5, 1)\n",
      "[3, 1, 3, 2, 1, 3, 1, 2, 1]\n",
      "Failed in 2 iterations..., from: (8, 4), to: (9, 4)\n",
      "<2>, trys more iterations...\n",
      "<2>, found the Solution Path: [3, 1, 2] to (10, 3)\n",
      "Succes! actions: [3, 1, 2], positions: [(8, 3), (9, 3), (10, 3)]\n",
      "\n",
      "<0> Action: |1|, Position: (5, 1), Target: (4, 2), Direction: North\n",
      "<1> Action: |3|, Position: (6, 5), Target: (7, 6), Direction: South\n",
      "<2> Action: |3|, Position: (8, 3), Target: (10, 2), Direction: West\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "Succes! actions: [3], positions: [(5, 2)], from: (5, 1), to: (5, 2)\n",
      "[1, 3, 2, 1, 3, 1, 2, 1]\n",
      "[1, 2]\n",
      "\n",
      "<0> Action: |3|, Position: (5, 2), Target: (4, 2), Direction: East\n",
      "<1> Action: |1|, Position: (6, 6), Target: (7, 6), Direction: East\n",
      "<2> Action: |1|, Position: (9, 3), Target: (10, 2), Direction: South\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "Succes! actions: [1], positions: [(4, 2)], from: (5, 2), to: (4, 2)\n",
      "[3, 2, 1, 3, 1, 2, 1]\n",
      "[2]\n",
      "\n",
      "<0> Action: |1|, Position: None, Target: (4, 2), Direction: North\n",
      "<1> Action: |3|, Position: None, Target: (7, 6), Direction: South\n",
      "<2> Action: |2|, Position: (10, 3), Target: (10, 2), Direction: South\n",
      "Rewards:  {0: 0, 1: 0, 2: -1.0}   [done= {0: True, 1: True, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "<1>, has reached the target!\n",
      "Failed in 2 iterations..., from: (10, 3), to: (10, 2)\n",
      "<2>, trys more iterations...\n",
      "Couln't find a Solution to a calculated traget!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "exceptions must derive from BaseException",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f7e95b18cf5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_agents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0maction_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e2abe593732a>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-20a3dc71a2cf>\u001b[0m in \u001b[0;36mget_n_action\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_n_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0;34m\"Error: Trying to get acces to an action with an undifinded timestep!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: exceptions must derive from BaseException"
     ]
    }
   ],
   "source": [
    "render = True\n",
    "\n",
    "try:\n",
    "    \n",
    "    \n",
    "    # Pass the Predictor to the observation builder\n",
    "    custom_obs_builder = ObservePredictions()\n",
    "\n",
    "    # Initiate Environment\n",
    "    env = RailEnv(width=10, height=15,\n",
    "                  rail_generator=complex_rail_generator(nr_start_goal=5, nr_extra=1, min_dist=8, max_dist=99999,\n",
    "                                                        seed=1), schedule_generator=complex_schedule_generator(),\n",
    "                  number_of_agents=3, obs_builder_object=custom_obs_builder)\n",
    "\n",
    "    obs, info = env.reset()\n",
    "    env_renderer = RenderTool(env, screen_width=2000, screen_height=2000)\n",
    "\n",
    "    # We render the initial step\n",
    "    if render : env_renderer.render_env(show=True, frames=False, show_observations=False, show_predictions=False)\n",
    "        \n",
    "        \n",
    "    # Calculate all the schedule of the Agents\n",
    "    schedules = calc_schedules(env)[\"schedule\"]\n",
    "        \n",
    "        \n",
    "    # Initialize the agent    \n",
    "    agent = [FirstStepsAgent(schedules[\"agent\" + str(i)], i) for i in range(env.get_num_agents())]\n",
    "    \n",
    "    \n",
    "    # Empty action dictionary which has the predicted actions in it for each step\n",
    "    action_dict = dict()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # For Loop with all the steps predicted by the agent\n",
    "    for step in range(25):\n",
    "        \n",
    "        for a in range(env.get_num_agents()):\n",
    "        \n",
    "            action_dict[a] = agent[a].act(obs[a])\n",
    "        \n",
    "        print()\n",
    "        # Do the actual step in the Enviroment based on the action_dict computed previously \n",
    "        obs, all_rewards, done, info = env.step(action_dict)\n",
    "        \n",
    "        for handle, action in action_dict.items():\n",
    "            print(f\"<{handle}> Action: |{action}|, Position: {env.agents[handle].position}, Target: {env.agents[handle].target}, Direction: {direction_to_str[env.agents[handle].direction]}\")\n",
    "        \n",
    "    \n",
    "\n",
    "        print(\"Rewards: \", all_rewards, \"  [done=\", done, \"]\", end=\"\\n\" + 50 * \"-\" + \"\\n\\n\")\n",
    "        \n",
    "        if render: env_renderer.render_env(show=True, frames=False, show_observations=False, show_predictions=True)\n",
    "            \n",
    "        if render: time.sleep(1)\n",
    "\n",
    "        if done[\"__all__\"]:\n",
    "            print(\"All done!\")\n",
    "            break\n",
    "            \n",
    "finally:\n",
    "    if render : env_renderer.close_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 0, 'y': 2, 't': 0},\n",
       " {'x': 1, 'y': 2, 't': 1},\n",
       " {'x': 2, 'y': 2, 't': 2},\n",
       " {'x': 3, 'y': 2, 't': 3},\n",
       " {'x': 4, 'y': 2, 't': 4},\n",
       " {'x': 5, 'y': 2, 't': 5},\n",
       " {'x': 5, 'y': 3, 't': 6},\n",
       " {'x': 6, 'y': 3, 't': 7},\n",
       " {'x': 7, 'y': 3, 't': 8},\n",
       " {'x': 7, 'y': 4, 't': 9},\n",
       " {'x': 7, 'y': 5, 't': 10},\n",
       " {'x': 7, 'y': 6, 't': 11}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedules[\"agent1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open_window - pyglet\n"
     ]
    }
   ],
   "source": [
    "custom_obs_builder = ObservePredictions()\n",
    "\n",
    "env = RailEnv(width=10, height=15,\n",
    "                  rail_generator=complex_rail_generator(nr_start_goal=5, nr_extra=1, min_dist=8, max_dist=99999,\n",
    "                                                        seed=1), schedule_generator=complex_schedule_generator(),\n",
    "                  number_of_agents=3, obs_builder_object=custom_obs_builder)\n",
    "\n",
    "obs, info = env.reset()\n",
    "\n",
    "env_renderer = RenderTool(env, screen_width=2000, screen_height=2000)\n",
    "env_renderer.render_env(show=True, frames=False, show_observations=False, show_predictions=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_schedules(env):\n",
    "    agents = []\n",
    "\n",
    "    # Map the Coordinates from Top left Origin ---> Bottom left Origin\n",
    "    # return [position[1] , env.height - 1 - position[0]]\n",
    "    \n",
    "    \n",
    "    def calc_coord(position):\n",
    "        return [position[0] , position[1]]\n",
    "\n",
    "\n",
    "    for handle, a in enumerate(env.agents):\n",
    "        agent = {\"goal\" : calc_coord(a.target), \"name\" : \"agent\" + str(handle), \"start\" : calc_coord(a.initial_position)}\n",
    "\n",
    "        agents.append(agent)\n",
    "\n",
    "\n",
    "    obstacles = []\n",
    "    for y in range(env.width):\n",
    "        for x in range(env.height):\n",
    "            if not True in env.get_valid_directions_on_grid(x, y):\n",
    "                obstacles.append(calc_coord((x, y)))\n",
    "\n",
    "    res_dict = {\"agents\" : agents, \"map\" : {\"dimensions\" : [env.height, env.width], \"obstacles\" : obstacles}}\n",
    "\n",
    "\n",
    "    f = open(\"test.yaml\", \"w\")\n",
    "    yaml.dump(res_dict, f)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    subprocess.run([\"./../../libMultiRobotPlanning-master/build/ecbs\",  \"-i\",  \"test.yaml\" , \"-o\", \"output.yaml\"], check=True)\n",
    "\n",
    "    with open(\"output.yaml\") as output_file:\n",
    "          yaml_out = yaml.load(output_file, Loader=yaml.FullLoader)\n",
    "            \n",
    "    return yaml_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "North 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-412b8ecf129a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection_to_str\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_next_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-412b8ecf129a>\u001b[0m in \u001b[0;36mcalc_next_cell\u001b[0;34m(position, direction, handle)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_next_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpossible_transitions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossible_transitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "Debug = False\n",
    "\n",
    "# Position, action, cost, direction\n",
    "def calc_next_cell(position, direction, handle):\n",
    "    \n",
    "    possible_transitions = env.rail.get_transitions(*position, direction)\n",
    "\n",
    "    if all(d == 0 for d in possible_transitions):\n",
    "        print(\"This Direction is not permissable!\")\n",
    "        return -1\n",
    "    \n",
    "    next_cells = []\n",
    "    # Loop trough all the possible dirrections the agent can reach from current direction\n",
    "    for d in [(direction + i) % 4 for i in range(-1, 2)]:\n",
    "        \n",
    "        if possible_transitions[d]:\n",
    "            \n",
    "            # Die neue Position, wenn man die jeweilige direction \n",
    "            new_position = get_new_position(position, d)\n",
    "            \n",
    "            \n",
    "            # Die Distanz von einer Position zum Ziel des jeweiligen Agenten\n",
    "            dist = env.distance_map.get()[handle, new_position[0], new_position[1], d]\n",
    "            \n",
    "            # Check the given directions and map it to the corresponding action\n",
    "            if d == direction:\n",
    "                if Debug: print(f\"Action forward, to: {new_position}, dist: {dist}\")\n",
    "                next_cells.append((new_position, 2, dist, d))\n",
    "                \n",
    "            \n",
    "            elif (d + 1) % 4 == direction:\n",
    "                if Debug: print(f\"Action left, to: {new_position}, dist: {dist}\")\n",
    "                next_cells.append((new_position, 1, dist, d))\n",
    "                \n",
    "            elif (d - 1) % 4 == direction:\n",
    "                if Debug: print(f\"Action right, to: {new_position}, dist: {dist}\") \n",
    "                next_cells.append((new_position, 3, dist, d))\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        # Check if the transition is an dead End\n",
    "        if possible_transitions[(direction + 2) % 4] == 1:\n",
    "            direction = (direction + 2) % 4\n",
    "\n",
    "            # Die neue Position, wenn man die jeweilige direction \n",
    "            new_position = get_new_position(position, direction)\n",
    "\n",
    "\n",
    "            # Die Distanz von einer Position zum Ziel des jeweiligen Agenten\n",
    "            dist = env.distance_map.get()[handle, new_position[0], new_position[1], direction]\n",
    "\n",
    "            if Debug: print(f\"Dead End, to: {new_position}, dist: {dist}\")\n",
    "            next_cells.append((new_position, 2, dist, direction))\n",
    "    \n",
    "    return next_cells\n",
    "            \n",
    "\n",
    "for i in range(4):\n",
    "    print(direction_to_str[i], i)\n",
    "    print(calc_next_cell((2, 1), i, 2))\n",
    "    print(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-20a3dc71a2cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# Position, action, direction, goal position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0ma_star\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;31m# a_star(2, (2, 0), 3, (2, 4))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-20a3dc71a2cf>\u001b[0m in \u001b[0;36ma_star\u001b[0;34m(handle, position, direction, goal_position, iterations)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mA_Star_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_Star_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msucces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0msucc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_next_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msucc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-412b8ecf129a>\u001b[0m in \u001b[0;36mcalc_next_cell\u001b[0;34m(position, direction, handle)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_next_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpossible_transitions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossible_transitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "\n",
    "\n",
    "class A_Star_result():\n",
    "    succes = 1\n",
    "    fail = 2\n",
    "    \n",
    "    def __init__(self, status, actions=[], positions=[], iterations=-1):\n",
    "        self.status = status\n",
    "        self.actions = actions\n",
    "        self.positions = positions\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.status == A_Star_result.succes:\n",
    "            return f\"Succes! actions: {self.actions}, positions: {self.positions}\"\n",
    "        else:\n",
    "            return f\"Failed in {self.iterations} iterations...\"\n",
    "        \n",
    "    def is_goal(self):\n",
    "        return len(self.actions) == 0\n",
    "    \n",
    "    def get_n_action(self, n):\n",
    "        if n >= len(self.actions):\n",
    "            raise \"Error: Trying to get acces to an action with an undifinded timestep!\"\n",
    "            \n",
    "        return self.actions[n]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, position, parent, action, cost, direction):\n",
    "        self.position = position\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.cost = cost\n",
    "        self.direction = direction\n",
    "        \n",
    "        self.state = (position, direction)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.cost < other.cost\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"|p: {self.position}, a: {self.action}, c: {self.cost}|\"\n",
    "        \n",
    "def make_root_node(postion, direction):\n",
    "    return Node(postion, None, None, 0, direction)\n",
    "\n",
    "def make_node(position, parent, action, cost, direction):\n",
    "    return Node(position, parent, action, parent.cost + cost, direction)\n",
    "\n",
    "def extract_solution(node):\n",
    "    sol = []\n",
    "    sol_pos = []\n",
    "    while node.parent is not None:\n",
    "        sol.append(node.action)\n",
    "        sol_pos.append(node.position)\n",
    "        node = node.parent\n",
    "    \n",
    "    return (sol[::-1], sol_pos[::-1])\n",
    "\n",
    "\n",
    "\n",
    "def a_star(handle, position, direction, goal_position, iterations=100):\n",
    "    open_list = []\n",
    "    heapq.heappush(open_list, make_root_node(position, direction))\n",
    "    \n",
    "    closed_list = []\n",
    "    distance = {}\n",
    "    \n",
    "    i = 0\n",
    "    while len(open_list) > 0 and i <= iterations:\n",
    "        \n",
    "        node = heapq.heappop(open_list)\n",
    "        \n",
    "        if node.state not in closed_list or node.cost < distance[node.state]:\n",
    "            \n",
    "            closed_list.append(node.state)\n",
    "            distance[node.state] = node.cost\n",
    "            \n",
    "            if node.position == goal_position:\n",
    "                res = extract_solution(node)\n",
    "                return A_Star_result(A_Star_result.succes, res[0], res[1])\n",
    "            \n",
    "            succ = calc_next_cell(node.position, node.direction, handle)\n",
    "            \n",
    "            for n in succ:\n",
    "                heapq.heappush(open_list, make_node(n[0], node, n[1], n[2], n[3]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        i += 1  # Make sure the Iterations are not that big\n",
    "                \n",
    "    return A_Star_result(A_Star_result.fail, iterations=i)\n",
    "\n",
    "# Position, action, direction, goal position\n",
    "a_star(2, (7, 5), 2, (8, 3))\n",
    "# a_star(2, (2, 0), 3, (2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnvAgent(initial_position=(13, 0), initial_direction=2, direction=2, target=(4, 2), moving=False, speed_data={'position_fraction': 0.0, 'speed': 1.0, 'transition_action_on_cellexit': 0.0}, malfunction_data={'malfunction': 0, 'malfunction_rate': 0.0, 'next_malfunction': 0, 'nr_malfunctions': 0, 'moving_before_malfunction': False}, handle=0, status=<RailAgentStatus.READY_TO_DEPART: 0>, position=None, old_direction=None, old_position=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Environment\n",
    "env = RailEnv(width=10, height=15,\n",
    "                  rail_generator=complex_rail_generator(nr_start_goal=5, nr_extra=1, min_dist=8, max_dist=99999,\n",
    "                                                        seed=1), schedule_generator=complex_schedule_generator(),\n",
    "                  number_of_agents=3, obs_builder_object=custom_obs_builder)\n",
    "\n",
    "obs, info = env.reset()\n",
    "env.agents[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fb72859d323b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_schedules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"schedule\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_computed_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "S = calc_schedules(env)[\"schedule\"]\n",
    "\n",
    "\n",
    "\n",
    "def get_computed_path(handle):\n",
    "    global S\n",
    "\n",
    "    s = S[\"agent\" + str(handle)]\n",
    "    \n",
    "    position_dict = []\n",
    "    for t in range(len(s)):\n",
    "        x, y, _ = s[t].values()\n",
    "\n",
    "        position_dict.append((x, y))\n",
    "\n",
    "    return(position_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent0': [{'x': 13, 'y': 0, 't': 0},\n",
       "  {'x': 12, 'y': 0, 't': 1},\n",
       "  {'x': 11, 'y': 0, 't': 2},\n",
       "  {'x': 10, 'y': 0, 't': 3},\n",
       "  {'x': 9, 'y': 0, 't': 4},\n",
       "  {'x': 8, 'y': 0, 't': 5},\n",
       "  {'x': 7, 'y': 0, 't': 6},\n",
       "  {'x': 6, 'y': 0, 't': 7},\n",
       "  {'x': 6, 'y': 1, 't': 8},\n",
       "  {'x': 5, 'y': 1, 't': 9},\n",
       "  {'x': 5, 'y': 2, 't': 10},\n",
       "  {'x': 4, 'y': 2, 't': 11}],\n",
       " 'agent1': [{'x': 0, 'y': 2, 't': 0},\n",
       "  {'x': 1, 'y': 2, 't': 1},\n",
       "  {'x': 2, 'y': 2, 't': 2},\n",
       "  {'x': 3, 'y': 2, 't': 3},\n",
       "  {'x': 4, 'y': 2, 't': 4},\n",
       "  {'x': 5, 'y': 2, 't': 5},\n",
       "  {'x': 5, 'y': 3, 't': 6},\n",
       "  {'x': 6, 'y': 3, 't': 7},\n",
       "  {'x': 7, 'y': 3, 't': 8},\n",
       "  {'x': 7, 'y': 4, 't': 9},\n",
       "  {'x': 7, 'y': 5, 't': 10},\n",
       "  {'x': 7, 'y': 6, 't': 11}],\n",
       " 'agent2': [{'x': 5, 'y': 9, 't': 0},\n",
       "  {'x': 5, 'y': 8, 't': 1},\n",
       "  {'x': 5, 'y': 7, 't': 2},\n",
       "  {'x': 5, 'y': 6, 't': 3},\n",
       "  {'x': 6, 'y': 6, 't': 4},\n",
       "  {'x': 7, 'y': 6, 't': 5},\n",
       "  {'x': 7, 'y': 5, 't': 6},\n",
       "  {'x': 7, 'y': 4, 't': 7},\n",
       "  {'x': 8, 'y': 4, 't': 8},\n",
       "  {'x': 9, 'y': 4, 't': 9},\n",
       "  {'x': 10, 'y': 4, 't': 10},\n",
       "  {'x': 10, 'y': 3, 't': 11},\n",
       "  {'x': 10, 'y': 2, 't': 12}]}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = calc_schedules(env)[\"schedule\"]\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnvAgent(initial_position=(0, 2), initial_direction=0, direction=2, target=(7, 6), moving=False, speed_data={'position_fraction': 0.0, 'speed': 1.0, 'transition_action_on_cellexit': 3}, malfunction_data={'malfunction': 0, 'malfunction_rate': 0.0, 'next_malfunction': 0, 'nr_malfunctions': 0, 'moving_before_malfunction': False}, handle=1, status=<RailAgentStatus.DONE_REMOVED: 3>, position=None, old_direction=1, old_position=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.agents[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
