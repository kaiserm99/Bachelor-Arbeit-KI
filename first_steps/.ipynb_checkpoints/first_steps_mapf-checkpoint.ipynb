{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisieren:\n",
    "../../libMultiRobotPlanning-master/example/visualize.py test.yaml output.yaml\n",
    "\n",
    "\n",
    "Basic Info:\n",
    "[North, East, South, West]\n",
    "DO_NOTHING= 0 MOVE_FORWARD= 2 MOVE_LEFT= 1 MOVE_RIGHT= 3 STOP_MOVING= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import yaml\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from typing import Optional, List, Dict\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from flatland.core.env import Environment\n",
    "from flatland.core.env_observation_builder import ObservationBuilder\n",
    "from flatland.core.grid.grid_utils import coordinate_to_position\n",
    "from flatland.envs.predictions import ShortestPathPredictorForRailEnv\n",
    "from flatland.envs.rail_env import RailEnv\n",
    "from flatland.envs.rail_generators import complex_rail_generator\n",
    "from flatland.envs.schedule_generators import complex_schedule_generator\n",
    "from flatland.utils.ordered_set import OrderedSet\n",
    "from flatland.utils.rendertools import RenderTool\n",
    "from flatland.core.grid.grid4_utils import get_new_position\n",
    "\n",
    "from flatland.utils.misc import str2bool\n",
    "\n",
    "\n",
    "random.seed(100)\n",
    "np.random.seed(100)\n",
    "\n",
    "direction_to_str = {0: \"North\", 1: \"East\", 2: \"South\", 3: \"West\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstStepsAgent:\n",
    "\n",
    "    def __init__(self, handle, schedule):        \n",
    "        self.result_schedule = schedule\n",
    "        self.handle = handle\n",
    "        \n",
    "        self.init = 0\n",
    "        \n",
    "\n",
    "    def act(self, sch):\n",
    "        \"\"\"\n",
    "        :param state: input is the observation of the agent\n",
    "        :return: returns an action\n",
    "        \"\"\"\n",
    "        \n",
    "        # \"Ignore\" the first step and just start with a forward move\n",
    "        if self.init == 0:\n",
    "            self.init = 1\n",
    "            \n",
    "            return 2\n",
    "        \n",
    "        elif self.init == 1:\n",
    "            \n",
    "            # Get the position and the direction of the agent based on the observation\n",
    "            pos = obs.position\n",
    "            direction = obs.direction\n",
    "\n",
    "            # Get the the calculated position where the agent has to move\n",
    "            target = obs.target\n",
    "\n",
    "            # Search in the System for the actions to get to the goal\n",
    "            self.result_schedule = a_star(self.handle, pos, direction, target)\n",
    "        \n",
    "            self.init = 2\n",
    "            return self.result_schedule.pop(0)\n",
    "\n",
    "        \n",
    "        elif self.init == 2 and not self.result_schedule.is_empty():\n",
    "            \n",
    "            return self.result_schedule.pop(0)\n",
    "        \n",
    "        elif self.init == 2 and self.result_schedule.is_empty():\n",
    "\n",
    "            return 0            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Observation():\n",
    "    def __init__(self, position, direction, target):\n",
    "        self.position = position \n",
    "        self.direction = direction\n",
    "        self.target = target\n",
    "\n",
    "class ObservePredictions(ObservationBuilder):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def get_many(self, handles: Optional[List[int]] = None) -> Dict[int, np.ndarray]:\n",
    "        observations = {}\n",
    "        \n",
    "\n",
    "        # Collect all the different observation for all the agents\n",
    "        for h in handles:\n",
    "            observations[h] = self.get(h)\n",
    "\n",
    "        return observations\n",
    "\n",
    "    def get(self, handle: int = 0) -> np.ndarray:\n",
    "        \n",
    "        agent = self.env.agents[handle]\n",
    "        \n",
    "        # self.env.dev_pred_dict[handle] = get_computed_path(handle)\n",
    "        \n",
    "        return Observation(agent.position, agent.direction, agent.target)\n",
    "\n",
    "    def set_env(self, env: Environment):\n",
    "        super().set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0> Action: |2|, Position: (9, 8), Target: (8, 0), Direction: East\n",
      "<1> Action: |2|, Position: (0, 3), Target: (8, 2), Direction: North\n",
      "<2> Action: |2|, Position: (2, 0), Target: (0, 9), Direction: West\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "<0> Action: |2|, Position: (9, 7), Target: (8, 0), Direction: West\n",
      "<1> Action: |2|, Position: (1, 3), Target: (8, 2), Direction: South\n",
      "<2> Action: |2|, Position: (2, 1), Target: (0, 9), Direction: East\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "<0> Action: |2|, Position: (9, 6), Target: (8, 0), Direction: West\n",
      "<1> Action: |2|, Position: (2, 3), Target: (8, 2), Direction: South\n",
      "<2> Action: |2|, Position: (2, 2), Target: (0, 9), Direction: East\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "<0> Action: |2|, Position: (9, 5), Target: (8, 0), Direction: West\n",
      "<1> Action: |2|, Position: (3, 3), Target: (8, 2), Direction: South\n",
      "<2> Action: |2|, Position: (2, 3), Target: (0, 9), Direction: East\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "<0> Action: |2|, Position: (9, 4), Target: (8, 0), Direction: West\n",
      "<1> Action: |2|, Position: (4, 3), Target: (8, 2), Direction: South\n",
      "<2> Action: |2|, Position: (2, 4), Target: (0, 9), Direction: East\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "<0> Action: |2|, Position: (9, 3), Target: (8, 0), Direction: West\n",
      "<1> Action: |2|, Position: (5, 3), Target: (8, 2), Direction: South\n",
      "<2> Action: |2|, Position: (2, 5), Target: (0, 9), Direction: East\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "<0> Action: |2|, Position: (9, 2), Target: (8, 0), Direction: West\n",
      "<1> Action: |2|, Position: (6, 3), Target: (8, 2), Direction: South\n",
      "<2> Action: |2|, Position: (2, 6), Target: (0, 9), Direction: East\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "<0> Action: |2|, Position: (9, 1), Target: (8, 0), Direction: West\n",
      "<1> Action: |2|, Position: (7, 3), Target: (8, 2), Direction: South\n",
      "<2> Action: |2|, Position: (2, 7), Target: (0, 9), Direction: East\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "<0> Action: |2|, Position: (9, 0), Target: (8, 0), Direction: West\n",
      "<1> Action: |3|, Position: (7, 2), Target: (8, 2), Direction: West\n",
      "<2> Action: |2|, Position: (2, 8), Target: (0, 9), Direction: East\n",
      "Rewards:  {0: -1.0, 1: -1.0, 2: -1.0}   [done= {0: False, 1: False, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "<0> Action: |3|, Position: None, Target: (8, 0), Direction: North\n",
      "<1> Action: |1|, Position: None, Target: (8, 2), Direction: South\n",
      "<2> Action: |1|, Position: (1, 8), Target: (0, 9), Direction: North\n",
      "Rewards:  {0: 0, 1: 0, 2: -1.0}   [done= {0: True, 1: True, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "<0> Action: |0|, Position: None, Target: (8, 0), Direction: North\n",
      "<1> Action: |0|, Position: None, Target: (8, 2), Direction: South\n",
      "<2> Action: |3|, Position: (1, 9), Target: (0, 9), Direction: East\n",
      "Rewards:  {0: 0, 1: 0, 2: -1.0}   [done= {0: True, 1: True, 2: False, '__all__': False} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "<0> Action: |0|, Position: None, Target: (8, 0), Direction: North\n",
      "<1> Action: |0|, Position: None, Target: (8, 2), Direction: South\n",
      "<2> Action: |1|, Position: None, Target: (0, 9), Direction: North\n",
      "Rewards:  {0: 1.0, 1: 1.0, 2: 1.0}   [done= {0: True, 1: True, 2: True, '__all__': True} ]\n",
      "--------------------------------------------------\n",
      "\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "render = False\n",
    "\n",
    "try:\n",
    "    \n",
    "    \n",
    "    # Pass the Predictor to the observation builder\n",
    "    custom_obs_builder = ObservePredictions()\n",
    "\n",
    "    # Initiate Environment\n",
    "    env = RailEnv(width=10, height=10,\n",
    "                  rail_generator=complex_rail_generator(nr_start_goal=5, nr_extra=1, min_dist=8, max_dist=99999,\n",
    "                                                        seed=1), schedule_generator=complex_schedule_generator(),\n",
    "                  number_of_agents=3, obs_builder_object=custom_obs_builder)\n",
    "\n",
    "    obs, info = env.reset()\n",
    "    env_renderer = RenderTool(env, screen_width=2000, screen_height=2000)\n",
    "\n",
    "    # We render the initial step\n",
    "    if render : env_renderer.render_env(show=True, frames=False, show_observations=False, show_predictions=False)\n",
    "        \n",
    "    # Initialize the agent    \n",
    "    agent = [FirstStepsAgent(handle) for handle in range(env.get_num_agents())]\n",
    "    \n",
    "    \n",
    "    # Empty action dictionary which has the predicted actions in it for each step\n",
    "    action_dict = dict()\n",
    "    \n",
    "    # For Loop with all the steps predicted by the agent\n",
    "    for step in range(25):\n",
    "        \n",
    "        for a in range(env.get_num_agents()):\n",
    "        \n",
    "            action_dict[a] = agent[a].act(obs[a])\n",
    "        \n",
    "        # Do the actual step in the Enviroment based on the action_dict computed previously \n",
    "        obs, all_rewards, done, info = env.step(action_dict)\n",
    "        \n",
    "        for handle, action in action_dict.items():\n",
    "            print(f\"<{handle}> Action: |{action}|, Position: {env.agents[handle].position}, Target: {env.agents[handle].target}, Direction: {direction_to_str[env.agents[handle].direction]}\")\n",
    "\n",
    "        print(\"Rewards: \", all_rewards, \"  [done=\", done, \"]\", end=\"\\n\" + 50 * \"-\" + \"\\n\\n\")\n",
    "        \n",
    "        if render: env_renderer.render_env(show=True, frames=False, show_observations=False, show_predictions=False)\n",
    "            \n",
    "        if render: time.sleep(1)\n",
    "\n",
    "        if done[\"__all__\"]:\n",
    "            print(\"All done!\")\n",
    "            break\n",
    "            \n",
    "finally:\n",
    "    if render : env_renderer.close_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "North 0\n",
      "This Direction is not permissable!\n",
      "-1\n",
      "--------------------------------------------------\n",
      "\n",
      "East 1\n",
      "This Direction is not permissable!\n",
      "-1\n",
      "--------------------------------------------------\n",
      "\n",
      "South 2\n",
      "This Direction is not permissable!\n",
      "-1\n",
      "--------------------------------------------------\n",
      "\n",
      "West 3\n",
      "[((2, 1), 2, 10.0, 1)]\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Debug = False\n",
    "\n",
    "# Position, action, cost, direction\n",
    "def calc_next_cell(position, direction, handle):\n",
    "    \n",
    "    possible_transitions = env.rail.get_transitions(*position, direction)\n",
    "\n",
    "    if all(d == 0 for d in possible_transitions):\n",
    "        print(\"This Direction is not permissable!\")\n",
    "        return -1\n",
    "    \n",
    "    next_cells = []\n",
    "    # Loop trough all the possible dirrections the agent can reach from current direction\n",
    "    for d in [(direction + i) % 4 for i in range(-1, 2)]:\n",
    "        \n",
    "        if possible_transitions[d]:\n",
    "            \n",
    "            # Die neue Position, wenn man die jeweilige direction \n",
    "            new_position = get_new_position(position, d)\n",
    "            \n",
    "            \n",
    "            # Die Distanz von einer Position zum Ziel des jeweiligen Agenten\n",
    "            dist = env.distance_map.get()[handle, new_position[0], new_position[1], d]\n",
    "            \n",
    "            # Check the given directions and map it to the corresponding action\n",
    "            if d == direction:\n",
    "                if Debug: print(f\"Action forward, to: {new_position}, dist: {dist}\")\n",
    "                next_cells.append((new_position, 2, dist, d))\n",
    "                \n",
    "            \n",
    "            elif (d + 1) % 4 == direction:\n",
    "                if Debug: print(f\"Action left, to: {new_position}, dist: {dist}\")\n",
    "                next_cells.append((new_position, 1, dist, d))\n",
    "                \n",
    "            elif (d - 1) % 4 == direction:\n",
    "                if Debug: print(f\"Action right, to: {new_position}, dist: {dist}\") \n",
    "                next_cells.append((new_position, 3, dist, d))\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        # Check if the transition is an dead End\n",
    "        if possible_transitions[(direction + 2) % 4] == 1:\n",
    "            direction = (direction + 2) % 4\n",
    "\n",
    "            # Die neue Position, wenn man die jeweilige direction \n",
    "            new_position = get_new_position(position, direction)\n",
    "\n",
    "\n",
    "            # Die Distanz von einer Position zum Ziel des jeweiligen Agenten\n",
    "            dist = env.distance_map.get()[handle, new_position[0], new_position[1], direction]\n",
    "\n",
    "            if Debug: print(f\"Dead End, to: {new_position}, dist: {dist}\")\n",
    "            next_cells.append((new_position, 2, dist, direction))\n",
    "    \n",
    "    return next_cells\n",
    "            \n",
    "\n",
    "for i in range(4):\n",
    "    print(direction_to_str[i], i)\n",
    "    print(calc_next_cell((2, 0), i, 2))\n",
    "    print(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "\n",
    "class A_Star_result():\n",
    "    succes = 1\n",
    "    fail = 2\n",
    "    \n",
    "    def __init__(self, status=succes, actions=[], positions=[], iterations=-1):\n",
    "        self.status = status\n",
    "        self.actions = actions\n",
    "        self.positions = positions\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.status == A_Star_result.succes:\n",
    "            return f\"Succes! actions: {self.actions}, positions: {self.positions}\"\n",
    "        else:\n",
    "            return f\"Failed in {self.iterations} iterations...\"\n",
    "        \n",
    "    def is_empty(self):\n",
    "        return len(self.actions) == 0\n",
    "    \n",
    "    def get_n_action(self, n):\n",
    "        if n < 0 or n >= len(self.actions):\n",
    "            raise \"Error: Trying to get acces to an action with an undifinded timestep!\"\n",
    "            \n",
    "        return self.actions[n]\n",
    "    \n",
    "    def pop(self, n):\n",
    "        if n < 0 or n >= len(self.actions):\n",
    "            raise \"Error: Trying to get acces to an action with an undifinded timestep!\"\n",
    "        \n",
    "        self.positions.pop(n)\n",
    "        return self.actions.pop(n)\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, position, parent, action, cost, direction):\n",
    "        self.position = position\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.cost = cost\n",
    "        self.direction = direction\n",
    "        \n",
    "        self.state = (position, direction)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.cost < other.cost\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"|p: {self.position}, a: {self.action}, c: {self.cost}|\"\n",
    "        \n",
    "def make_root_node(position, direction):\n",
    "    return Node(position, None, None, 0, direction)\n",
    "\n",
    "def make_node(position, parent, action, cost, direction):\n",
    "    return Node(position, parent, action, cost, direction)\n",
    "\n",
    "def extract_solution(node):\n",
    "    sol = []\n",
    "    sol_pos = []\n",
    "    while node.parent is not None:\n",
    "        sol.append(node.action)\n",
    "        sol_pos.append(node.position)\n",
    "        node = node.parent\n",
    "    \n",
    "    return (sol[::-1], sol_pos[::-1])\n",
    "\n",
    "\n",
    "\n",
    "def a_star(handle, position, direction, goal_position, iterations=100):\n",
    "    open_list = []\n",
    "    heapq.heappush(open_list, make_root_node(position, direction))\n",
    "    \n",
    "    closed_list = []\n",
    "    distance = {}\n",
    "    \n",
    "    i = 0\n",
    "    while len(open_list) > 0 and i <= iterations:\n",
    "        \n",
    "        node = heapq.heappop(open_list)\n",
    "        \n",
    "        if node.state not in closed_list or node.cost < distance[node.state]:\n",
    "            \n",
    "            closed_list.append(node.state)\n",
    "            distance[node.state] = node.cost\n",
    "            \n",
    "            if node.position == goal_position:\n",
    "                res = extract_solution(node)\n",
    "                return A_Star_result(A_Star_result.succes, res[0], res[1])\n",
    "            \n",
    "            succ = calc_next_cell(node.position, node.direction, handle)\n",
    "            \n",
    "            for n in succ:\n",
    "                heapq.heappush(open_list, make_node(n[0], node, n[1], n[2], n[3]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        i += 1  # Make sure the Iterations are not that big\n",
    "                \n",
    "    return A_Star_result(A_Star_result.fail, iterations=i)\n",
    "\n",
    "# Position, action, direction, goal position\n",
    "# a_star(2, (7, 5), 2, (8, 3))\n",
    "# a_star(2, (2, 0), 3, (2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[|p: (9, 8), a: None, c: 0|], [|p: (0, 3), a: None, c: 0|], [|p: (2, 1), a: 2, c: 10.0|]],\n",
       " [[|p: (9, 8), a: None, c: 0|], [|p: (1, 3), a: 2, c: 8.0|], [|p: (2, 0), a: None, c: 0|]],\n",
       " [[|p: (9, 8), a: None, c: 0|], [|p: (1, 3), a: 2, c: 8.0|], [|p: (2, 1), a: 2, c: 10.0|]],\n",
       " [[|p: (9, 7), a: 2, c: 8.0|], [|p: (0, 3), a: None, c: 0|], [|p: (2, 0), a: None, c: 0|]],\n",
       " [[|p: (9, 7), a: 2, c: 8.0|], [|p: (0, 3), a: None, c: 0|], [|p: (2, 1), a: 2, c: 10.0|]],\n",
       " [[|p: (9, 7), a: 2, c: 8.0|], [|p: (1, 3), a: 2, c: 8.0|], [|p: (2, 0), a: None, c: 0|]],\n",
       " [[|p: (9, 7), a: 2, c: 8.0|], [|p: (1, 3), a: 2, c: 8.0|], [|p: (2, 1), a: 2, c: 10.0|]]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools \n",
    "\n",
    "# Pass the Predictor to the observation builder\n",
    "custom_obs_builder = ObservePredictions()\n",
    "\n",
    "# Initiate Environment\n",
    "\n",
    "env = RailEnv(width=10, height=10,\n",
    "                  rail_generator=complex_rail_generator(nr_start_goal=5, nr_extra=1, min_dist=8, max_dist=99999,\n",
    "                                                        seed=1), schedule_generator=complex_schedule_generator(),\n",
    "                  number_of_agents=3, obs_builder_object=custom_obs_builder)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "env = RailEnv(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        rail_generator=rail_from_file(\"../scratch/test-envs/Test_1/Level_1.pkl\"),\n",
    "        number_of_agents=3\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "obs, info = env.reset()\n",
    "env.step({i : 2 for i in range(env.get_num_agents())})\n",
    "\n",
    "\n",
    "\n",
    "class StateNodes():\n",
    "    \n",
    "    def __init__(self, node_lst):\n",
    "        \n",
    "        self.node_lst = node_lst\n",
    "        self.cost = 0\n",
    "        self.state = []\n",
    "        \n",
    "        for n in node_lst:\n",
    "            self.cost += n[0].cost\n",
    "            self.state.append((n[0].position, n[0].direction))\n",
    "            \n",
    "        self.state = tuple(self.state)\n",
    "        self.parent = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.node_lst}\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        res = True\n",
    "        for handle in range(len(self.node_lst)):\n",
    "\n",
    "            if self.get_node(handle).position != other.get_node(handle).position:\n",
    "                res = False\n",
    "                \n",
    "        return res\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.cost < other.cost\n",
    "    \n",
    "    def get_node(self, handle):\n",
    "        return self.node_lst[handle][0]\n",
    "\n",
    "# Position, action, cost, direction\n",
    "def get_next_states(node):\n",
    "    \n",
    "    # This should be an list of StateNodes.\n",
    "    res = []\n",
    "    \n",
    "    # This loop gives a binary counter, so every state of the correspondig agent get expanded\n",
    "    for lst in itertools.product([0,1], repeat=len(node.node_lst)):\n",
    "        \n",
    "        next_states = []\n",
    "        \n",
    "        for handle, apply in enumerate(lst):\n",
    "            \n",
    "            if apply == 1:\n",
    "                \n",
    "                curr_agent = node.get_node(handle)\n",
    "                \n",
    "                next_cells = calc_next_cell(curr_agent.position, curr_agent.direction, handle)\n",
    "                \n",
    "                next_nodes = [make_node(pos, curr_agent, act, cost, dire) for pos, act, cost, dire in next_cells]\n",
    "                \n",
    "                next_states.append(next_nodes)\n",
    "            \n",
    "            # Do nothing and do not expand this state\n",
    "            elif apply == 0:\n",
    "                \n",
    "                ol = node.node_lst[handle]\n",
    "                \n",
    "                next_states.append(ol)\n",
    "            \n",
    "        prod = list(itertools.product(*next_states))\n",
    "        for s in prod:\n",
    "            \n",
    "            state = StateNodes([[x] for x in s])\n",
    "            \n",
    "            if state.cost != np.inf:\n",
    "            \n",
    "                res.append(state)\n",
    "            \n",
    "    return res[1:]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "states = []\n",
    "for handle in range(env.get_num_agents()):\n",
    "    agent = env.agents[handle]\n",
    "    \n",
    "    position = agent.position\n",
    "    direction = agent.direction\n",
    "    \n",
    "    states.append([make_root_node(position, direction)])\n",
    "    \n",
    "    \n",
    "get_next_states(StateNodes(states))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[|p: (9, 8), a: None, c: 0|], [|p: (0, 3), a: None, c: 0|], [|p: (2, 1), a: 2, c: 10.0|]]\n",
      "[[|p: (9, 8), a: None, c: 0|], [|p: (0, 3), a: None, c: 0|], [|p: (2, 2), a: 2, c: 9.0|]]\n",
      "[[|p: (9, 8), a: None, c: 0|], [|p: (0, 3), a: None, c: 0|], [|p: (2, 3), a: 2, c: 8.0|]]\n",
      "[[|p: (9, 7), a: 2, c: 8.0|], [|p: (1, 3), a: 2, c: 8.0|], [|p: (2, 4), a: 2, c: 7.0|]]\n",
      "[[|p: (9, 6), a: 2, c: 7.0|], [|p: (2, 3), a: 2, c: 7.0|], [|p: (2, 5), a: 2, c: 6.0|]]\n",
      "[[|p: (9, 5), a: 2, c: 6.0|], [|p: (3, 3), a: 2, c: 6.0|], [|p: (2, 6), a: 2, c: 5.0|]]\n",
      "[[|p: (9, 4), a: 2, c: 5.0|], [|p: (4, 3), a: 2, c: 5.0|], [|p: (2, 7), a: 2, c: 4.0|]]\n",
      "[[|p: (9, 3), a: 2, c: 4.0|], [|p: (5, 3), a: 2, c: 4.0|], [|p: (2, 8), a: 2, c: 3.0|]]\n",
      "[[|p: (9, 2), a: 2, c: 3.0|], [|p: (6, 3), a: 2, c: 3.0|], [|p: (1, 8), a: 1, c: 2.0|]]\n",
      "[[|p: (9, 1), a: 2, c: 2.0|], [|p: (7, 3), a: 2, c: 2.0|], [|p: (1, 9), a: 3, c: 1.0|]]\n",
      "[[|p: (9, 0), a: 2, c: 1.0|], [|p: (7, 2), a: 3, c: 1.0|], [|p: (0, 9), a: 1, c: 0.0|]]\n",
      "[[|p: (8, 0), a: 3, c: 0.0|], [|p: (8, 2), a: 1, c: 0.0|], [|p: (0, 9), a: 1, c: 0.0|]]\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "\n",
    "\n",
    "# nodes is an StatesNodes Object\n",
    "def make_state_node(state, parent):\n",
    "\n",
    "    nodes = state.node_lst\n",
    "    \n",
    "    res = StateNodes(nodes)\n",
    "    res.cost += parent.cost\n",
    "    res.parent = parent\n",
    "    \n",
    "    return res\n",
    "\n",
    "def extract_state_solution(state):\n",
    "    sol = []\n",
    "    \n",
    "    while state.parent is not None:\n",
    "        sol.append(state)\n",
    "        state = state.parent\n",
    "    \n",
    "    return sol[::-1]\n",
    "\n",
    "\n",
    "def a_star_big(init_state, goal_state):\n",
    "    open_list = []\n",
    "    heapq.heappush(open_list, init_state)\n",
    "    \n",
    "    closed_list = []\n",
    "    distance = {}\n",
    "    \n",
    "    while len(open_list) > 0:\n",
    "        \n",
    "        node = heapq.heappop(open_list)\n",
    "        \n",
    "        if node.state not in closed_list or node.cost < distance[node.state]:\n",
    "            \n",
    "            closed_list.append(node.state)\n",
    "            distance[node.state] = node.cost\n",
    "            \n",
    "            # StateNodes == StateNodes --> position of all should be the same\n",
    "            if node == goal_state:\n",
    "                res = extract_state_solution(node)\n",
    "                return res\n",
    "            \n",
    "            succ = get_next_states(node)\n",
    "            \n",
    "            for n in succ:\n",
    "                heapq.heappush(open_list, make_state_node(n, node))\n",
    "\n",
    "\n",
    "\n",
    "pos = []\n",
    "for handle in range(env.get_num_agents()):\n",
    "    agent = env.agents[handle]\n",
    "    \n",
    "    position = agent.position\n",
    "    direction = agent.direction\n",
    "    \n",
    "    pos.append([make_root_node(position, direction)])\n",
    "    \n",
    "\n",
    "goal_pos = []\n",
    "for handle in range(env.get_num_agents()):\n",
    "    agent = env.agents[handle]\n",
    "    \n",
    "    goal_pos.append([make_root_node(agent.target, -1)])\n",
    "\n",
    "\n",
    "result_star = a_star_big(StateNodes(pos), StateNodes(goal_pos))\n",
    "\n",
    "for i in result_star:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[|p: (9, 7), a: 2, c: 8.0|,\n",
       " |p: (9, 6), a: 2, c: 7.0|,\n",
       " |p: (9, 5), a: 2, c: 6.0|,\n",
       " |p: (9, 4), a: 2, c: 5.0|,\n",
       " |p: (9, 3), a: 2, c: 4.0|,\n",
       " |p: (9, 2), a: 2, c: 3.0|,\n",
       " |p: (9, 1), a: 2, c: 2.0|,\n",
       " |p: (9, 0), a: 2, c: 1.0|]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_state_solution(states, handle):\n",
    "    \n",
    "    sol = []\n",
    "    \n",
    "    for state in states:\n",
    "        if state.get_node(handle).cost != 0:\n",
    "            sol.append(state.get_node(handle))\n",
    "    \n",
    "    return sol\n",
    "\n",
    "extract_state_solution(result_star, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flatland.envs.rail_generators import rail_from_manual_specifications_generator\n",
    "from flatland.envs.rail_generators import rail_from_file\n",
    "\n",
    "def render_env(env):\n",
    "    env_renderer = RenderTool(env, gl=\"PILSVG\")\n",
    "    env_renderer.render_env()\n",
    "\n",
    "    image = env_renderer.get_image()\n",
    "    pil_image = PIL.Image.fromarray(image)\n",
    "    display(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open_window - pyglet\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MapObservation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-12dc403fbb87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0menv_renderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_observations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_predictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmap_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMapObservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MapObservation' is not defined"
     ]
    }
   ],
   "source": [
    "render = True\n",
    "\n",
    "try:\n",
    "\n",
    "    \n",
    "    env = RailEnv(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        rail_generator=rail_from_file(\"../scratch/test-envs/Test_1/Level_1.pkl\"),\n",
    "        number_of_agents=2\n",
    "    )\n",
    "    \n",
    "\n",
    "    env.reset()\n",
    "    env.step({i : 2 for i in range(env.get_num_agents())})\n",
    "    \n",
    "    if render: env_renderer = RenderTool(env)\n",
    "\n",
    "    if render: env_renderer.render_env(show=True, frames=False, show_observations=False, show_predictions=False)\n",
    "    \n",
    "    map_obs = MapObservation(env)\n",
    "\n",
    "    \n",
    "    for handle in range(env.get_num_agents()):\n",
    "        map_obs.get_schedule(handle)\n",
    "    \n",
    "    \n",
    "    print(\"--\"*50)\n",
    "    \n",
    "    action_dict = dict()\n",
    "    for _ in range(40):\n",
    "    \n",
    "        for handle in range(env.get_num_agents()):\n",
    "        \n",
    "            action = map_obs.pop_action(handle, 0)\n",
    "            \n",
    "            env.dev_obs_dict[handle] = map_obs.get_positions(handle)\n",
    "            \n",
    "            action_dict[handle] = action\n",
    "            \n",
    "        env.step(action_dict)\n",
    "        \n",
    "        if render: env_renderer.render_env(show=True, frames=False, show_observations=True, show_predictions=False)\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "finally:\n",
    "    if render: env_renderer.close_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {i : [0] for i in range(env.get_num_agents())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [0]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v for v in d.values() if len(v) != 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
